[Adalflow-Auto-optimize LLM Applications](https://github.com/SylphAI-Inc/AdalFlow)

[Arize_AI-Prompt Optimization Using Datasets](https://colab.research.google.com/gist/exiao/9ff8d9e0db4462911ca5fd9aa99e82b6/product-manager-experiment.ipynb)


[Promptflow Prompt Flow For Rag](https://www.restack.io/p/promptflow-answer-prompt-flow-for-rag-cat-ai)

[Automatic prompt engineering](https://x.com/cwolferesearch/status/1841557739308286424)

1. Construct a “meta prompt” that asks the LLM to write a new prompt based on prior context (i.e., previous prompts and their performance metrics).
2. Generate new prompts with an “optimizer” LLM.
3. Evaluate these prompts using another LLM, producing an objective value / score.
4. Select prompts with the best scores.
5. Repeat steps 1-4 until we can’t find a better prompt.


Definitions:
- Meta-prompt: Meta prompts are instructions that guide an AI's behaviour or output in specific ways. They act as a framework for the AI's interpretation and response to subsequent prompts or queries. This article explores the concept of meta prompts, using examples from a system prompt designed for worksheet generation.
![Screenshot 2024-10-03 091834](https://github.com/user-attachments/assets/d92ae568-2154-425c-8f00-384400d14d23)


<img width="869" alt="Screenshot 2024-12-28 at 9 06 16 PM" src="https://github.com/user-attachments/assets/66b05885-dfeb-49c6-a031-54f6cb9de813" />

[resource](https://ihey.cc/rag/rag-query-optimization-howto/)
